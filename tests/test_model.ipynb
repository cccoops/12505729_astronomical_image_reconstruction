{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e4409",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2813321034.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    import TransformAndCacheDataset from best_cnn_unet\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import TransformAndCacheDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98d0ff2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "Failed",
     "evalue": "Fixture \"fake_image_path\" called directly. Fixtures are not meant to be called directly,\nbut are created automatically when test functions request them as parameters.\nSee https://docs.pytest.org/en/stable/explanation/fixtures.html for more information about fixtures, and\nhttps://docs.pytest.org/en/stable/deprecations.html#calling-fixtures-directly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailed\u001b[0m                                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 136\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# Verify input shape == output shape (U-Net requirement)\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m output\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m dummy_input\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPost-processing failed: Output shape mismatch!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 136\u001b[0m fake_img \u001b[38;5;241m=\u001b[39m \u001b[43mfake_image_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m test_preprocessing_shape(fake_img)\n\u001b[1;32m    139\u001b[0m test_model_output_shape\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/_pytest/fixtures.py:1299\u001b[0m, in \u001b[0;36mFixtureFunctionDefinition.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1293\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixture \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m called directly. Fixtures are not meant to be called directly,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut are created automatically when test functions request them as parameters.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://docs.pytest.org/en/stable/explanation/fixtures.html for more information about fixtures, and\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.pytest.org/en/stable/deprecations.html#calling-fixtures-directly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1298\u001b[0m     )\n\u001b[0;32m-> 1299\u001b[0m     \u001b[43mfail\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpytrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/_pytest/outcomes.py:163\u001b[0m, in \u001b[0;36m_Fail.__call__\u001b[0;34m(self, reason, pytrace)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, reason: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, pytrace: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m    162\u001b[0m     __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Failed(msg\u001b[38;5;241m=\u001b[39mreason, pytrace\u001b[38;5;241m=\u001b[39mpytrace)\n",
      "\u001b[0;31mFailed\u001b[0m: Fixture \"fake_image_path\" called directly. Fixtures are not meant to be called directly,\nbut are created automatically when test functions request them as parameters.\nSee https://docs.pytest.org/en/stable/explanation/fixtures.html for more information about fixtures, and\nhttps://docs.pytest.org/en/stable/deprecations.html#calling-fixtures-directly"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "import torch\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import time\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.metrics import structural_similarity as ssim_metric\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr_metric\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv2d -> ReLU) x2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "#TODO: Be able to reason about the network here\n",
    "class CnnUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CnnUNet, self).__init__()\n",
    "\n",
    "        # Encoder (Downsampling)\n",
    "        self.enc1 = DoubleConv(3, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.enc2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.enc3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(256, 512)\n",
    "\n",
    "        # Decoder (Upsampling + SKIP CONNECTIONS)\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = DoubleConv(512, 256) # Input is 512 because 256 (up3) + 256 (skip)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = DoubleConv(256, 128) # Input is 256 because 128 (up2) + 128 (skip)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = DoubleConv(128, 64)  # Input is 128 because 64 (up1) + 64 (skip)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(64, 3, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "        \n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "        \n",
    "        e3 = self.enc3(p2)\n",
    "        p3 = self.pool3(e3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)\n",
    "\n",
    "        # Decoder with Skips\n",
    "        # We concatenate the encoder output (e3) with the upsampled bottleneck (x)\n",
    "        x = self.up3(b)\n",
    "        x = torch.cat([x, e3], dim=1) \n",
    "        x = self.dec3(x)\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x = torch.cat([x, e2], dim=1)\n",
    "        x = self.dec2(x)\n",
    "\n",
    "        x = self.up1(x)\n",
    "        x = torch.cat([x, e1], dim=1)\n",
    "        x = self.dec1(x)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "\n",
    "# Helper to create a fake image if one doesn't exist\n",
    "@pytest.fixture\n",
    "def fake_image_path(tmp_path):\n",
    "    # Create a dummy white image 500x500\n",
    "    img = Image.new('RGB', (500, 500), color='white')\n",
    "    path = tmp_path / \"test_galaxy.jpg\"\n",
    "    img.save(path)\n",
    "    return str(path)\n",
    "\n",
    "def test_preprocessing_shape(fake_image_path):\n",
    "    \"\"\"Test that images are resized to 256x256 correctly.\"\"\"\n",
    "    # Mimic your Dataset logic\n",
    "    upscale_factor = 4\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256 // upscale_factor, 256 // upscale_factor)),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    img = Image.open(fake_image_path).convert(\"RGB\")\n",
    "    tensor = transform(img)\n",
    "    \n",
    "    # Check dimensions: [Channels, Height, Width]\n",
    "    assert tensor.shape == (3, 256, 256), \"Pre-processing failed: Shape is wrong!\"\n",
    "\n",
    "def test_model_output_shape():\n",
    "    \"\"\"Test that the model accepts input and returns correct output shape.\"\"\"\n",
    "    model = CnnUNet()\n",
    "    \n",
    "    # Create a random 'fake' batch of 2 images (Batch=2, C=3, H=256, W=256)\n",
    "    dummy_input = torch.randn(2, 3, 256, 256)\n",
    "    \n",
    "    # Pass through model\n",
    "    output = model(dummy_input)\n",
    "    \n",
    "    # Verify input shape == output shape (U-Net requirement)\n",
    "    assert output.shape == dummy_input.shape, \"Post-processing failed: Output shape mismatch!\"\n",
    "    \n",
    "fake_img = fake_image_path(\"\")\n",
    "    \n",
    "test_preprocessing_shape(fake_img)\n",
    "test_model_output_shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
